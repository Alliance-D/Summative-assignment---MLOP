events {
    worker_connections 1024;
}

http {
    # Upstream API servers (round-robin by default)
    upstream api_backend {
        # Adjust which servers are active based on test scenario
        server api1:8000;
        server api2:8000;
        server api3:8000;
        server api4:8000;
    }

    server {
        listen 80;
        
        # Increase timeouts for ML inference
        proxy_connect_timeout 300s;
        proxy_send_timeout 300s;
        proxy_read_timeout 300s;
        
        # Increase buffer sizes
        client_max_body_size 50M;
        
        location / {
            proxy_pass http://api_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Add response headers to track which container handled request
            add_header X-Upstream-Server $upstream_addr always;
        }
    }
}